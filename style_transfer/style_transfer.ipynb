{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7349936a",
      "metadata": {
        "id": "7349936a"
      },
      "source": [
        "## Theory\n",
        "- Content of original image to be retained in generated image\n",
        "- Style of reference image to be adopted to generated image\n",
        "\n",
        "## Loss\n",
        "$$loss = distance(style(ref\\space image) - style(generated\\space image)) + distance(content(org\\space image) - content(generated\\space image))$$\n",
        "\n",
        "distance is l2 norm\n",
        "\n",
        "### Content Loss\n",
        "Loss between the top layer\n",
        "### Style Loss\n",
        "Correlation of activation\n",
        "Loss for all the layers\n",
        "### Gram Matrix\n",
        "- Used in style loss because it uses all the layers\n",
        "\n",
        "$$loss = \\alpha content(loss) + \\beta style(loss)$$\n",
        "alpha - to be more than beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b13a6b",
      "metadata": {
        "id": "a1b13a6b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "import keras.backend as K\n",
        "from tensorflow.image import total_variation\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5718cb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5718cb1",
        "outputId": "54e996e5-853d-4a2d-d9e8-1857a1692901"
      },
      "outputs": [],
      "source": [
        "model = VGG16(include_top=False)\n",
        "model.trainable = False\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a073b16",
      "metadata": {
        "id": "8a073b16"
      },
      "outputs": [],
      "source": [
        "## For content transfer check the loss between block5_conv3 in both content image and generated image\n",
        "## For style transfer check the Gram matrix loss for block1_conv1, block2_conv1, block3_conv1, block4_conv1, block5_conv1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3370a19b",
      "metadata": {
        "id": "3370a19b"
      },
      "outputs": [],
      "source": [
        "def load_image(image_path, target_size=None):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img = img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649edffa",
      "metadata": {
        "id": "649edffa"
      },
      "outputs": [],
      "source": [
        "content = load_image('content_img.jpeg', [250, 250])\n",
        "style = load_image('ref_img.jpeg', [510, 510])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0cab70",
      "metadata": {
        "id": "7e0cab70"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "def deprocess(img):\n",
        "    # perform the inverse of the pre processing step\n",
        "    img[:, :, 0] += 103.939\n",
        "    img[:, :, 1] += 116.779\n",
        "    img[:, :, 2] += 123.68\n",
        "    # convert RGB to BGR\n",
        "    img = img[:, :, ::-1]\n",
        "\n",
        "    img = np.clip(img, 0, 255).astype('uint8')\n",
        "    return img\n",
        "\n",
        "def display_image(image):\n",
        "    # remove one dimension if image has 4 dimension\n",
        "    if len(image.shape) == 4:\n",
        "        img = np.squeeze(image, axis=0)\n",
        "\n",
        "    img = deprocess(img)\n",
        "\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587866c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "587866c4",
        "outputId": "caf687b7-8530-45bd-e457-0ccb1dbace41"
      },
      "outputs": [],
      "source": [
        "display_image(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48048c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "f48048c0",
        "outputId": "f05d0e89-1e90-4f1c-f14a-285f4f1785c6"
      },
      "outputs": [],
      "source": [
        "display_image(style)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f87f88",
      "metadata": {
        "id": "c7f87f88"
      },
      "outputs": [],
      "source": [
        "content_layer = 'block5_conv3'\n",
        "content_model = Model(model.input,\n",
        "                     model.get_layer(content_layer).output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c12ae55d",
      "metadata": {
        "id": "c12ae55d"
      },
      "outputs": [],
      "source": [
        "style_layers = ['block5_conv1',\n",
        "              'block4_conv1',\n",
        "              'block3_conv1',\n",
        "              'block2_conv1',\n",
        "              'block1_conv1']\n",
        "style_layers.sort()\n",
        "style_model = Model(model.input,\n",
        "                   [model.get_layer(layer).output for layer in style_layers])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7180f444",
      "metadata": {
        "id": "7180f444"
      },
      "outputs": [],
      "source": [
        "def content_loss(base, combination):\n",
        "    img_loss = content_model(base)\n",
        "    gen_loss = content_model(combination)\n",
        "    return K.sum(K.square(img_loss - gen_loss))\n",
        "\n",
        "def gram_matrix(features):\n",
        "    features = tf.reshape(features, [-1, features.shape[-1]])\n",
        "    return K.dot(features, K.transpose(features))\n",
        "\n",
        "def style_loss(style, combination):\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channel = 3\n",
        "    size = img_height * img_width\n",
        "    return K.sum(K.square(S-C))/(4 * (channel**2) * (size**2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "272593f6",
      "metadata": {
        "id": "272593f6"
      },
      "source": [
        "### Total Variation Loss\n",
        "To avoid blurring of the image due to increase in pixel size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "941fea2f",
      "metadata": {
        "id": "941fea2f"
      },
      "outputs": [],
      "source": [
        "genertaed_images = []\n",
        "def train_model(contnet_img, style_img, iterations=500, content_weight=2.5, style_weight=0.001, total_var_weight=1e-5):\n",
        "    content_img = load_image(contnet_img, [125, 125])\n",
        "    style_img = load_image(style_img, [125, 125])\n",
        "    generated_img = tf.Variable(content_img, dtype=tf.float32)\n",
        "    display_image(generated_img)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=3.5)\n",
        "\n",
        "    best_loss = np.inf\n",
        "    best_img = None\n",
        "    for i in range(iterations):\n",
        "        with tf.GradientTape() as tape:\n",
        "            C_loss = content_loss(content_img, generated_img)\n",
        "            S_loss_layers = style_model(style_img)\n",
        "            G_S_loss_layers = style_model(generated_img)\n",
        "            S_loss = 0\n",
        "            for S_loss_layer, G_loss_layer in zip(S_loss_layers, G_S_loss_layers):\n",
        "                S_loss += style_weight*style_loss(S_loss_layer, G_loss_layer)\n",
        "            V_loss = total_variation(generated_img)\n",
        "            T_loss = C_loss*content_weight + S_loss*style_weight/len(style_layers) + V_loss*total_var_weight\n",
        "\n",
        "        grads = tape.gradient(T_loss, generated_img)\n",
        "        opt.apply_gradients([(grads, generated_img)])\n",
        "\n",
        "        if T_loss < best_loss:\n",
        "            best_loss = T_loss\n",
        "            best_img = generated_img.numpy()\n",
        "\n",
        "        print(f'Iteration:{i}\\nLoss:{T_loss}')\n",
        "        genertaed_images.append(generated_img)\n",
        "    return best_img\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ffa459",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "23ffa459",
        "outputId": "ff37c798-5f5e-4cb6-b4e1-1910daee55ca"
      },
      "outputs": [],
      "source": [
        "img_height = 125; img_width = 125\n",
        "final_img = train_model('content_img.jpeg', 'ref_img.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "geg_FxgbDDB5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "geg_FxgbDDB5",
        "outputId": "5c70ce94-b75e-442c-b43e-05c48db47eb3"
      },
      "outputs": [],
      "source": [
        "display_image(genertaed_images[len(genertaed_images) - 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lE7zKrXpuwcW",
      "metadata": {
        "id": "lE7zKrXpuwcW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
